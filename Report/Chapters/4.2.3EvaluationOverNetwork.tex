Evaluation over the network is done using the requests python library creating HTTP requests to the \textit{evaluator} webservice that is created using the CherryPy Framework.
\paragraph{}
If no target function is specified and a target webservice is, then requests library is used to send the test arguments to the webservice so it can get the correct result. This result
is put with every set of test arguments in a dictionary and send to the evaluator together with an individual. Initially the idea was to have multiple evaluators processing the
individuals which meant making asynchronous requests to multiple webservices. However the complexity of the tast was too high and the development time for such a component would
of been too long, so there is only a single evaluator used.
\paragraph{}
The easy parsing of parameters in CherryPy made it comfortable to send individuals as parameters to the web service and their test arguments so they can be evaluated. Initially
the web service had to set up additional DEAP configuration in order to evaluate an individual and return the result. However there was a lot of complexity and dependencies were
too many and so it was later re-factored to parse the source code of an individual to the \textit{evaluator}. This resulted into simplification of the evaluator to 
a single simple method.

\begin{lstlisting}[language=Python,caption={The soruce of the evaluator},label={lst:evaluator}]
class BaseCherryPy:

    def evaluate(self,individual,arguments):
        arguments = eval(arguments)
        diff=0
        for i in arguments:
            sys.argv = i[0]
            with stdoutIO() as s:
                exec(individual) in {}
            try:
                res = float(s.getvalue())
                diff += (res - i[1])**2
            except:
                diff = sys.float_info.max
        return str(diff)

    evaluate.exposed=True
\end{lstlisting}

In order to run the evaluator the class that is ran by CherryPy needs to be either \textit{BaseCherryPy} or a class extending it. What \textit{BaseCherryPy} contains
is a method that has the exposed flag set to true that handles the sent individual. The client is always calling the method called \textit{evaluator} see \ref{lst:evaluate} with two parameters.
One is an individual in python source code and the second is a dictionary with test arguments and fitness values from target. What the method does is it sets the system arguments
of the python interpreter to the test arguments and after that executes the source code into a different context. Then by overwriting the \textit{contextmanager}\footnote{Note that the overwriting of contextmanager
wasn't done by me but the stackoverflow user isedev in the thread http://stackoverflow.com/questions/14708216/showing-current-output-from-exec-in-python handling this issue} the python standard output is
parsed back to the original context ( the one of the evaluator).